Using RCU (Read-Copy-Update) for synchronization
================================================

Read-copy update (RCU) is a synchronization mechanism that is used to
protect read-mostly data structures.  RCU is very efficient and scalable
on the read side (it is wait-free), and thus can make the read paths
extremely fast.

RCU supports concurrency between a single writer and multiple readers,
thus it is not used alone.  Typically, the write-side will use a lock to
serialize multiple updates, but other approaches are possible (e.g.,
restricting updates to a single task).  In QEMU, when a lock is used,
this will often be the "iothread mutex", also known as the "big QEMU
lock" (BQL).  Also, restricting updates to a single task is done in
QEMU using the "bottom half" API.

RCU is fundamentally a "wait-to-finish" mechanism.  The read side marks
sections of code with "critical sections", and the update side will wait
for the execution of all *currently running* critical sections before
proceeding, or before asynchronously executing a callback.

The key point here is that only the currently running critical sections
are waited for; critical sections that are started _after_ the beginning
of the wait do not extend the wait, despite running concurrently with
the updater.  This is the reason why RCU is more scalable than,
for example, reader-writer locks.  It is so much more scalable that
the system will have a single instance of the RCU mechanism; a single
mechanism can be used for an arbitrary number of "things", without
having to worry about things such as contention or deadlocks.

How is this possible?  The basic idea is to split updates in two phases,
"removal" and "reclamation".  During removal, we ensure that subsequent
readers will not be able to get a reference to the old data.  After
removal has completed, a critical section will not be able to access
the old data.  Therefore, critical sections that begin after removal
do not matter; as soon as all previous critical sections have finished,
there cannot be any readers who hold references to the data structure,
which may not be safely reclaimed (e.g., freed or unref'ed).

Here is a picutre:

        thread 1                  thread 2                  thread 3
    -------------------    ------------------------    -------------------
    enter RCU crit.sec.
           |                finish removal phase
           |                begin wait
           |                      |                    enter RCU crit.sec.
    exit RCU crit.sec             |                           |
                            complete wait                     |
                            begin reclamation phase           |
                                                       exit RCU crit.sec.


Note how thread 3 is still executing its critical section when thread 2
starts reclaiming data.  This is possible, because the old version of the
data structure was not accessible at the time thread 3 began executing
that critical section.


RCU API
=======

The core RCU API is small:

     void rcu_read_lock(void);

        Used by a reader to inform the reclaimer that the reader is
        entering an RCU read-side critical section.

     void rcu_read_unlock(void);

        Used by a reader to inform the reclaimer that the reader is
        exiting an RCU read-side critical section.  Note that RCU
        read-side critical sections may be nested and/or overlapping.

     void synchronize_rcu(void);

        Blocks until all pre-existing RCU read-side critical sections
        on all threads have completed.  This marks the end of the removal
        phase and the beginning of reclamation phase.

        Note that it would be valid for another update to come while
        synchronize_rcu is running.  Because of this, it is better that
        the updater releases any locks it may hold before calling
        synchronize_rcu.  If this is not possible (for example, because
        the updater is protected by the BQL), you can use call_rcu.

     void call_rcu1(struct rcu_head * head,
                    void (*func)(struct rcu_head *head));

        This function invokes func(head) after all pre-existing RCU
        read-side critical sections on all threads have completed.  This
        marks the end of the removal phase, with func taking care
        asynchronously of the reclamation phase.

        The foo struct needs to have an rcu_head structure added,
        perhaps as follows:

            struct foo {
                struct rcu_head rcu;
                int a;
                char b;
                long c;
            };

        so that the reclaimer function can fetch the struct foo address
        and free it:

            call_rcu1(foo_reclaim, &foo.rcu);

            void foo_reclaim(struct rcu_head *rp)
            {
                struct foo *fp = container_of(rp, struct foo, rcu);
                g_free(fp);
            }

        For the common case where the rcu_head member is the first of the
        struct, you can use the following macro.

     void call_rcu(T *p,
                   void (*func)(T *p),
                   field-name);

        call_rcu1 is typically used through this macro, in the common case
        where the "struct rcu_head" is the first field in the struct.  In
        the above case, one could have written simply:

            call_rcu(foo_reclaim, g_free, rcu);

     typeof(*p) rcu_dereference(p);
     typeof(*p) rcu_assign_pointer(p, typeof(*p) v);

        These macros are similar to atomic_mb_read() and atomic_mb_set()
        respectively.  However, they make some assumptions on the code
        that calls them, which allows a more optimized implementation.

        rcu_assign_pointer assumes that the update side is not going
        to read from the data structure after "publishing" the new
        values; that is, it assumes that all assignments happen at
        the very end of the removal phase.

        rcu_dereference assumes that whenever a single RCU critical
        section reads multiple shared data, these reads are either
        data-dependent or need no ordering.  This is almost always the
        case when using RCU.  If this were not the case, you can use
        atomic_mb_read() or smp_rmb().

        If you are going to be fetching multiple fields from the
        RCU-protected structure, repeated rcu_dereference() calls
        would look ugly and incur unnecessary overhead on Alpha CPUs.
        You can then do this:

        p = &rcu_dereference(&head);
        foo = head->foo;
        bar = head->bar;


RCU QUIESCENT STATES
====================

An efficient implementation of rcu_read_lock() and rcu_read_unlock()
relies on the availability of fast thread-local storage.  Unfortunately,
this is not possible on all the systems supported by QEMU (in particular
on many POSIX systems other than Linux and Solaris).

For this reason, QEMU's RCU implementation resorts to manual annotation
of "quiescent states", i.e. points where no RCU read-side critical
section can be active.  All threads created with qemu_thread_create
participate in the RCU mechanism and need to annotate such points.

Luckily, in most cases no manual annotation is needed, because waiting
on condition variables (qemu_cond_wait), semaphores (qemu_sem_wait,
qemu_sem_timedwait) or events (qemu_event_wait) implicitly marks the thread
as quiescent for the whole duration of the wait.  (There is an exception
for semaphore waits with a zero timeout).

Manual annotation is still needed in the following cases:

- threads that spend their sleeping time in the kernel, for example
  in a call to select(), poll(), sigwait() or WaitForMultipleObjects().
  The QEMU I/O thread is an example of this case.  When running under
  KVM, VCPUs are also in a quiescent state while running the guest.

- threads that perform a lot of I/O.  In QEMU, the workers used for
  aio=thread are an example of this case (see aio_worker in block/raw-*).

- threads that run continuously until they exit.  The migration thread
  is an example of this case.

Regarding the second case, note that the workers run in the QEMU thread
pool.  The thread pool uses semaphores for synchronization, hence it does
report quiescent states periodically.  However, in some cases (e.g. NFS
mounted with the "hard" option) the workers can take an arbitrarily long
amount of time.  When this happens, synchronize_rcu() will not exit and
call_rcu() callbacks will be delayed arbitrarily.  It is therefore a
good idea to mark I/O system calls as quiescence points in the worker
functions.


Marking quiescent states is done with the following three APIs:

     void rcu_quiescent_state(void);

        Marks a point in the execution of the current thread where no
        RCU read-side critical section can be active.

     void rcu_thread_offline(void);

        Marks the beginning of an "extended quiescent state" for the
        current thread, i.e. an interval of time during which no
        RCU read-side critical section can be active.

     void rcu_thread_online(void);

        Marks the end of an extended quiescent state for the current
        thread.


rcu_thread_offline() and rcu_thread_online() can be nested.  The end of
the extended quiescent state will coincide with the outermost call to
rcu_thread_online().


The following APIs can be used to use RCU in a thread that is not
created with qemu_thread_create():

     void rcu_register_thread(void);

        Mark a thread as taking part in the RCU mechanism.  Such a thread
        will have to report quiescent points regularly, either manually
        or through the QemuCond/QemuSemaphore/QemuEvent APIs.

     void rcu_unregister_thread(void);

        Mark a thread as not taking part anymore in the RCU mechanism.
        It is not a problem if such a thread reports quiescent points,
        either manually or by using the QemuCond/QemuSemaphore/QemuEvent
        APIs.

Note that these APIs are relatively heavyweight, should _not_ be
nested, and should not be called in threads that are created with
qemu_thread_create().


DIFFERENCES WITH LINUX
======================

- Waiting on a mutex is possible, though discouraged, within an RCU critical
  section.  This is because spinlocks are rarely (if ever) used in userspace
  programming; not allowing this would prevent upgrading an RCU read-side
  critical section to become an updater.

- rcu_dereference and rcu_assign_pointer take a _pointer_ to the variable
  being accessed.  Wrong usage will be detected by the compiler.

- call_rcu is a macro that has an extra argument (the name of the first
  field in the struct, which must be a struct rcu_head), and expects the
  type of the callback's argument to be the type of the first argument.
  call_rcu1 is the same as Linux's call_rcu.

- Quiescent points must be marked explicitly unless the thread uses
  condvars/semaphores/events for synchronization.  Note that mutexes
  do not report quiescent points (see the first item above).


RCU PATTERNS
============

Many patterns using read-writer locks translate directly to RCU, with
the advantages of higher scalability and deadlock immunity.

In general, RCU can be used whenever it is possible to create a new
"version" of a data structure every time the updater runs.  This may
sound like a very strict restriction, however:

- the updater does not mean "everything that writes to a data structure",
  but rather "everything that involves a reclamation step".  See the
  array example below

- in some cases, creating a new version of a data structure may actually
  be very cheap.  For example, modifying the "next" pointer of a singly
  linked list is effectively creating a new version of the list.

Here are some frequently-used RCU idioms that are worth noting.


RCU list processing
-------------------

TBD (not yet used in QEMU)


RCU reference counting
----------------------

Because grace periods are not allowed to complete while there is an RCU
read-side critical section in progress, the RCU read-side primitives
may be used as a restricted reference-counting mechanism.  For example,
consider the following code fragment:

    rcu_read_lock();
    p = rcu_dereference(&foo);
    /* do something with p. */
    rcu_read_unlock();

The RCU read-side critical section ensures that the value of "p" remains
valid until after the rcu_read_unlock().  In some sense, it is acquiring
a reference to p that is later released when the critical section ends.
The write side looks simply like this (with appropriate locking):

    qemu_mutex_lock(&foo_mutex);
    old = foo;
    rcu_assign_pointer(&foo, new);
    qemu_mutex_unlock(&foo_mutex);
    synchronize_rcu();
    free(old);

If the processing cannot be done purely within the critical section, it
is possible to combine this idiom with a "real" reference count:

    rcu_read_lock();
    p = rcu_dereference(&foo);
    foo_ref(p);
    rcu_read_unlock();
    /* do something with p. */
    foo_unref(p);

The write side can be like this:

    qemu_mutex_lock(&foo_mutex);
    old = foo;
    rcu_assign_pointer(&foo, new);
    qemu_mutex_unlock(&foo_mutex);
    synchronize_rcu();
    foo_unref(old);

or with call_rcu:

    qemu_mutex_lock(&foo_mutex);
    old = foo;
    rcu_assign_pointer(&foo, new);
    qemu_mutex_unlock(&foo_mutex);
    call_rcu(foo_unref, old, rcu);

In both cases, the write side only performs removal.  Reclamation
happens when the last reference to a "foo" object is dropped.
Using synchronize_rcu() is undesirably expensive, because the
last reference may be dropped on the read side.  Hence you can
use call_rcu() instead:

     foo_unref(struct foo *p) {
        if (atomic_fetch_dec(&p->refcount) == 1) {
            call_rcu(foo_destroy, p, rcu);
        }
    }


Note that the same idioms would be possible with reader/writer
locks:

    read_lock(&foo_rwlock);         write_mutex_lock(&foo_rwlock);
    p = foo;                        p = foo;
    /* do something with p. */      foo = new;
    read_unlock(&foo_rwlock);       free(p);
                                    write_mutex_unlock(&foo_rwlock);
                                    free(p);

    ------------------------------------------------------------------

    read_lock(&foo_rwlock);         write_mutex_lock(&foo_rwlock);
    p = foo;                        old = foo;
    foo_ref(p);                     foo = new;
    read_unlock(&foo_rwlock);       write_mutex_unlock(&foo_rwlock);
    /* do something with p. */      foo_unref(old);
    foo_unref(p);

foo_unref could use a mechanism such as bottom halves to move deallocation
out of hot paths.


RCU resizable arrays
--------------------

Resizable arrays can be used with RCU.  The expensive RCU synchronization
(or call_rcu) only needs to take place when the array is resized.
The two items to take care of are:

- ensuring that the old version of the array is available between removal
  and reclamation;

- avoiding mismatches in the read side between the array data and the
  array size.

The first problem is avoided simply by not using realloc.  Instead,
each resize will allocate a new array and copy the old data into it.
The second problem would arise if the size and the data pointers were
two members of a larger struct:

    struct mystuff {
        ...
        int data_size;
        int data_alloc;
        T   *data;
        ...
    };

Instead, we store the size of the array with the array itself:

    struct arr {
        int size;
        int alloc;
        T   data[];
    };
    struct arr *global_array;

    read side:
        rcu_read_lock();
        struct arr *array = rcu_dereference(&global_array);
        x = i < array->size ? array->data[i] : -1;
        rcu_read_unlock();
        return x;

    write side (running under a lock):
        if (global_array->size == global_array->alloc) {
            /* Creating a new version.  */
            new_array = g_malloc(sizeof(struct arr) +
                                 global_array->alloc * 2 * sizeof(T));
            new_array->size = global_array->size;
            new_array->alloc = global_array->alloc * 2;
            memcpy(new_array->data, global_array->data,
                   global_array->alloc * sizeof(T));

            /* Removal phase.  */
            old_array = global_array;
            rcu_assign_pointer(&new_array->data, new_array);
            synchronize_rcu();

            /* Reclamation phase.  */
            free(old_array);
        }
